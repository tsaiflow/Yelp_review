{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#### MANY TO MANY KARPATHY VERSION\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM,TimeDistributed,SimpleRNN\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import random\n",
    "import sys\n",
    "import string\n",
    "\n",
    "chars=['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~']\n",
    "#text = open('full_sample_300.txt').read()\n",
    "\n",
    "\n",
    "#chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewmanser/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:5: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "/Users/andrewmanser/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:5: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(1024, return_sequences=True, input_shape=(None, 95))`\n"
     ]
    }
   ],
   "source": [
    "#We need dropout (unlike many to one model) as it can memorize the training set\n",
    "#Dropout hyperparameter could be tuned further\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(1024,input_dim=len(chars),return_sequences=True)) \n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(1024,return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(TimeDistributed(Dense(len(chars))))\n",
    "model.add(Activation('softmax'))\n",
    "model.load_weights(\"More-Dropout-all-Karpathy-00-0.6968.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(lr=0.0002)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed string --> <SOR>g\n",
      "The generated text is\n",
      "<SOR>great place for breakfast or anything. French Toast w/ sausage LINKS is the best, except for the steak and eggs. Burgers and wings both great; just generally good food<EOR>\"\n",
      "\"<SOR>I had the eggplanttofu with chicken katsu .. So good :D<EOR>\"\n",
      "\"<SOR>The food was delicious, service was speedy, restrooms"
     ]
    }
   ],
   "source": [
    "#CURRENT VERSION GREEDY ONLY, NO TEMPERATURE CONTROLS YET\n",
    "#STARTING REVIEW WITH <SOR> PLUS A RANDOM CHOICE OF LETTERS\n",
    "#seed_string=\"<SOR>\"+random.choice(string.ascii_letters)\n",
    "seed_string=\"<SOR>\"+\"g\"\n",
    "print (\"seed string -->\", seed_string)\n",
    "print ('The generated text is')\n",
    "sys.stdout.write(seed_string),\n",
    "\n",
    "#final=seed_string+''\n",
    "\n",
    "for i in range(300):\n",
    "    x=np.zeros((1, len(seed_string), len(chars)))\n",
    "    for t, char in enumerate(seed_string):\n",
    "        x[0, t, char_indices[char]] = 1.\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    #print (np.argmax(preds[7]))\n",
    "    next_index=np.argmax(preds[len(seed_string)-1])\n",
    "    #next_index = sample(preds, 0.8)\n",
    "    #next_index=sample(preds[len(seed_string)-1],0.1)\n",
    "    \n",
    "    #next_index=np.argmax(preds[len(seed_string)-11])\n",
    "    #print (preds.shape)\n",
    "    #print (preds)\n",
    "    #next_index = sample(preds, 1) #diversity is 1\n",
    "    next_char = indices_char[next_index]\n",
    "    seed_string = seed_string + next_char\n",
    "    \n",
    "    #final+=next_char\n",
    "    sys.stdout.write(next_char)\n",
    "#print(final)\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
